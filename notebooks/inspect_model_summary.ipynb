{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdulla.almansoori/miniconda3/envs/floral/lib/python3.10/site-packages/tensorflow_probability/python/__init__.py:57: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.__version__) <\n",
      "/home/abdulla.almansoori/miniconda3/envs/floral/lib/python3.10/site-packages/tensorflow_model_optimization/__init__.py:65: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if (distutils.version.LooseVersion(tf.version.VERSION) <\n",
      "/home/abdulla.almansoori/miniconda3/envs/floral/lib/python3.10/site-packages/google/rpc/__init__.py:20: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.rpc')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  pkg_resources.declare_namespace(__name__)\n",
      "/home/abdulla.almansoori/miniconda3/envs/floral/lib/python3.10/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import os\n",
    "import glob\n",
    "import hydra\n",
    "from floral.training.utils import instantiate_model\n",
    "\n",
    "TASK_CONFIG_DIR = \"../floral/conf/task\"\n",
    "TASK = \"shakespeare\"  # <--- choose task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_names(conf_dir):\n",
    "    config_names = []\n",
    "    for fname in glob.glob(os.path.join(conf_dir, \"*\")):\n",
    "        config_name = os.path.basename(fname).replace('.yaml', '')\n",
    "        if not config_name.startswith(\"_\"):\n",
    "            config_names.append(config_name)\n",
    "    return list(sorted(config_names))\n",
    "\n",
    "\n",
    "available_tasks = get_config_names(TASK_CONFIG_DIR)\n",
    "assert TASK in available_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:flwr:FLoRAL: rank = 0.99999\n",
      "DEBUG:flwr:FLoRAL: num of clusters = 4\n",
      "DEBUG:flwr:FLoRAL: base model parameters = 3217194\n",
      "DEBUG:flwr:FLoRAL: lora model parameters = 183368\n",
      "DEBUG:flwr:FLoRAL: routing model parameters = 4\n",
      "DEBUG:flwr:FLoRAL: total model parameters = 3400566\n",
      "DEBUG:flwr:FLoRAL: increase in parameters = 5.70%\n",
      "DEBUG:flwr:==============================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Kernel Shape              Param #                   Param %                   Mult-Adds\n",
      "==============================================================================================================================================================================================\n",
      "Floral                                   [1, 20]                   [20, 90]                  --                        --                             --                   --\n",
      "├─Router: 1-1                            --                        [4]                       --                        4                           0.00%                   16\n",
      "├─SimpleRNN: 1-2                         [1, 20]                   [20, 90]                  --                        --                             --                   --\n",
      "│    └─Embedding: 2-1                    [1, 20]                   [1, 20, 8]                --                        720                         0.02%                   720\n",
      "│    └─LSTM: 2-2                         [1, 20, 8]                [1, 20, 512]              --                        3,170,304                  93.23%                   63,406,080\n",
      "│    └─Linear: 2-3                       [1, 20, 512]              [1, 20, 90]               --                        46,170                      1.36%                   46,170\n",
      "├─ModuleDict: 1-3                        --                        --                        --                        --                             --                   --\n",
      "│    └─LoRAList: 2-4                     [1, 20, 512]              [1, 20, 90]               --                        --                             --                   --\n",
      "│    │    └─LinearLoRA: 3-1              [1, 20, 512]              [1, 20, 90]               --                        --                             --                   --\n",
      "│    │    │    └─Linear: 4-1             [1, 20, 512]              [1, 20, 76]               --                        38,912                      1.14%                   38,912\n",
      "│    │    │    └─Linear: 4-2             [1, 20, 76]               [1, 20, 90]               --                        6,930                       0.20%                   6,930\n",
      "│    │    └─LinearLoRA: 3-2              [1, 20, 512]              [1, 20, 90]               --                        --                             --                   --\n",
      "│    │    │    └─Linear: 4-3             [1, 20, 512]              [1, 20, 76]               --                        38,912                      1.14%                   38,912\n",
      "│    │    │    └─Linear: 4-4             [1, 20, 76]               [1, 20, 90]               --                        6,930                       0.20%                   6,930\n",
      "│    │    └─LinearLoRA: 3-3              [1, 20, 512]              [1, 20, 90]               --                        --                             --                   --\n",
      "│    │    │    └─Linear: 4-5             [1, 20, 512]              [1, 20, 76]               --                        38,912                      1.14%                   38,912\n",
      "│    │    │    └─Linear: 4-6             [1, 20, 76]               [1, 20, 90]               --                        6,930                       0.20%                   6,930\n",
      "│    │    └─LinearLoRA: 3-4              [1, 20, 512]              [1, 20, 90]               --                        --                             --                   --\n",
      "│    │    │    └─Linear: 4-7             [1, 20, 512]              [1, 20, 76]               --                        38,912                      1.14%                   38,912\n",
      "│    │    │    └─Linear: 4-8             [1, 20, 76]               [1, 20, 90]               --                        6,930                       0.20%                   6,930\n",
      "==============================================================================================================================================================================================\n",
      "Total params: 3,400,566\n",
      "Trainable params: 3,400,566\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 63.64\n",
      "==============================================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.20\n",
      "Params size (MB): 13.60\n",
      "Estimated Total Size (MB): 13.81\n",
      "==============================================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "with hydra.initialize(version_base=None, config_path=\"../floral/conf\"):\n",
    "    cfg = hydra.compose(config_name=\"base\", overrides=[f\"task@_global_={TASK}\",\n",
    "                                                       f\"method@_global_=floral\"])\n",
    "    cfg.task = TASK\n",
    "    cfg.method = \"floral\"\n",
    "    # cfg.floral.rank = 0.999\n",
    "    cfg.floral.num_clusters = 4\n",
    "    cfg.floral.min_rank = 1\n",
    "    # cfg.floral.bias = False\n",
    "    # cfg.floral.use_embeddinglora = False\n",
    "    # cfg.floral.use_convlora = False\n",
    "    # cfg.floral.use_normlora = True\n",
    "    # cfg.floral.convlora_method = \"out\"\n",
    "\n",
    "base_model = hydra.utils.instantiate(cfg.model)\n",
    "model = instantiate_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.embedding.weight\n",
      "base_model.lstm.weight_ih_l0\n",
      "base_model.lstm.weight_hh_l0\n",
      "base_model.lstm.bias_ih_l0\n",
      "base_model.lstm.bias_hh_l0\n",
      "base_model.lstm.weight_ih_l1\n",
      "base_model.lstm.weight_hh_l1\n",
      "base_model.lstm.bias_ih_l1\n",
      "base_model.lstm.bias_hh_l1\n",
      "base_model.fc.weight\n",
      "base_model.fc.bias\n",
      "router.weight\n",
      "lora_modules.lora(base_model/fc).0.layer_in.weight\n",
      "lora_modules.lora(base_model/fc).0.layer_out.weight\n",
      "lora_modules.lora(base_model/fc).0.layer_out.bias\n",
      "lora_modules.lora(base_model/fc).1.layer_in.weight\n",
      "lora_modules.lora(base_model/fc).1.layer_out.weight\n",
      "lora_modules.lora(base_model/fc).1.layer_out.bias\n",
      "lora_modules.lora(base_model/fc).2.layer_in.weight\n",
      "lora_modules.lora(base_model/fc).2.layer_out.weight\n",
      "lora_modules.lora(base_model/fc).2.layer_out.bias\n",
      "lora_modules.lora(base_model/fc).3.layer_in.weight\n",
      "lora_modules.lora(base_model/fc).3.layer_out.weight\n",
      "lora_modules.lora(base_model/fc).3.layer_out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.state_dict().items():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
